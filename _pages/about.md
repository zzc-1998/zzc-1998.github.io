---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class='anchor' id='about-me'></span>

- I am currently a PhD Candidate at Shanghai Jiao Tong University. My interests cover quality assessment and low-level vision.
- I am working on project [**Q-Future**: Visual Evaluation with Foundation Models](https://github.com/Q-Future) (co-founder)

# üî• News
- *2024.08*: &nbsp;‚ö°‚ö° Co-Instruct is accepted by ECCV 2024 as oral
- *2024.08*: &nbsp;‚ö°‚ö° Q-Bench+ has been accepted by IEEE TPAMI
- *2024.07*: &nbsp;‚ö°‚ö° Seven papers (five oral) have been accepted by ACM MM 2024
- *2024.06*: &nbsp;‚ö°‚ö° Two papers have been accepted by ICIP 2024
- *2024.05*: &nbsp;‚ö°‚ö° Get the NSFC fund for PhD students (Ëç£Ëé∑ÂçöÂ£´ÁîüÂõΩËá™ÁÑ∂Âü∫Èáë)
- *2024.04*: &nbsp;‚ö°‚ö° Two papers (one oral) have been accepted by ICME 2024
- *2024.03*: &nbsp;‚ö°‚ö° The **First Prize** of the *Short-form UGC Video Quality Assessment* for NTIRE2024-CVPRW 
- *2024.02*: &nbsp;‚ö°‚ö° Organizing the *Quality Assessment for AI-Generated Content - Track 1/2 Image/Video* for NTIRE2024-CVPRW 
- *2024.01*: &nbsp;‚ö°‚ö° Q-Instruct get accepted by CVPR 2024!
- *2024.01*: &nbsp;‚ö°‚ö° Q-Bench get accepted by ICLR2024 as a Spotlight paper!
- *2023.04*: &nbsp;‚ö°‚ö° The **First Prize** of the *IEEE ICIP Point Cloud Visual Quality Assessment Grand Challenge*
- *2022.04*: &nbsp;‚ö°‚ö° The **First Prize** of the *IEEE ICIP Grand Challenge: Video Distortion Detection and Classification in the Context of Video Surveillance*


# üìù Selected Publications

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IEEE TPAMI</div><img src='https://github.com/zzc-1998/zzc-1998.github.io/blob/main/images/qbench+.png?raw=true' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Q-Bench+: A Benchmark for Multi-modal Foundation Models on Low-level Vision from Single Images to Pairs 
- **Zicheng Zhang\***, Haoning Wu\*, Erli Zhang, Guangtao Zhai, Weisi Lin
- [**[Paper]**](https://arxiv.org/pdf/2402.07116) [**[Repo]**](https://github.com/Q-Future/Q-Bench)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2024 (Spotlight)</div><img src='https://github.com/zzc-1998/zzc-1998.github.io/blob/main/images/q-bench.jpg?raw=true' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-Level Vision 
- Haoning Wu\*, **Zicheng Zhang\***, Erli Zhang\*, Chaofeng Chen, Liang Liao, Annan Wang, Chunyi Li, Wenxiu Sun, Qiong Yan, Guangtao Zhai, Weisi Lin
- [**[Paper]**](https://arxiv.org/abs/2309.14181) [**[Repo]**](https://github.com/Q-Future/Q-Bench)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024 </div><img src='https://github.com/Q-Future/Q-Instruct/blob/main/new_q_instruct.png?raw=true' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Q-Instruct: Improving Low-level Visual Abilities for Multi-modality Foundation Models 
- Haoning Wu\*, **Zicheng Zhang\***, Erli Zhang\*, Chaofeng Chen1, Liang Liao, Annan Wang, Kaixin Xu, Chunyi Li, Jingwen Hou, Guangtao Zhai, Geng Xue, Wenxiu Sun, Qiong Yan, Weisi Lin
- [**[Paper]**](https://arxiv.org/abs/2312.17090) [**[Repo]**](https://github.com/Q-Future/Q-Instruct)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2024 </div><img src='https://github.com/Q-Future/Q-Align/blob/main/fig/q-align-syllabus.png?raw=true' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Q-Align: Teaching LMMs for Visual Scoring via Discrete Text-Defined Levels
- Haoning Wu\*, **Zicheng Zhang\***, Weixia Zhang, Chaofeng Chen, Liang Liao, Chunyi Li, Yixuan Gao, Annan Wang, Erli Zhang, Wenxiu Sun, Qiong Yan, Xiongkuo Min, Guangtao Zhai, Weisi Lin
- [**[Paper]**](https://arxiv.org/abs/2311.06783) [**[Repo]**](https://github.com/Q-Future/Q-Align)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">MM 2024 (Oral)</div><img src='https://github.com/Q-Future/LMM-PCQA/blob/main/spotlight.png?raw=true' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

LMM-PCQA: Assisting Point Cloud Quality Assessment with LMM
- **Zicheng Zhang**, Haoning Wu, Yingjie Zhou, Chunyi Li, Wei Sun, Chaofeng Chen, Xiongkuo Min, Xiaohong Liu, Weisi Lin, Guangtao Zhai
- [**[Paper]**](https://arxiv.org/abs/2404.18203) [**[Repo]**](https://github.com/Q-Future/LMM-PCQA)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCAI 2023</div><img src='https://github.com/zzc-1998/MM-PCQA/blob/main/pics/framework.png?raw=true' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

MM-PCQA: Multi-Modal Learning for No-reference Point Cloud Quality Assessment 
- **Zicheng Zhang**, Wei Sun, Xiongkuo Min, Quan Zhou, Jun He, Qiyuan Wang, Guangtao Zhai
- [**[Paper]**](https://www.ijcai.org/proceedings/2023/0195.pdf) [**[Repo]**](https://github.com/zzc-1998/MM-PCQA)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IEEE TCSVT</div><img src='https://github.com/zzc-1998/NR-3DQA/blob/main/framework.jpg?raw=true' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

No-reference quality assessment for 3d colored point cloud and mesh models 
- **Zicheng Zhang**, Wei Sun, Xiongkuo Min, Tao Wang, Wei Lu, Guangtao Zhai
- [**[Paper]**](https://arxiv.org/pdf/2107.02041.pdf) [**[Repo]**](https://github.com/zzc-1998/NR-3DQA)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IEEE TMM</div><img src='https://github.com/zzc-1998/VQA_PC/blob/main/video.gif?raw=true' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Evaluating Point Cloud from Moving Camera Videos: A No-Reference Metric 
- **Zicheng Zhang**, Wei Sun, Yucheng Zhu, Xiongkuo Min, Wei Wu, Ying Chen, Guangtao Zhai
- [**[Paper]**](https://arxiv.org/abs/2208.14085) [**[Repo]**](https://github.com/zzc-1998/VQA_PC)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM TOMM</div><img src='https://github.com/zzc-1998/CGIQA6K/raw/main/overview.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Subjective and Objective Quality Assessment for in-the-Wild Computer Graphics Images 
- **Zicheng Zhang**, Wei Sun, Yingjie Zhou, Jun Jia, Zhichao Zhang, Jing Liu, Xiongkuo Min, Guangtao Zhai
- [**[Paper]**](https://arxiv.org/abs/2303.08050) [**[Repo]**](https://github.com/zzc-1998/CGIQA6K)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM TOMM</div><img src='https://github.com/zzc-1998/GMS-3DQA/blob/main/gms-3dqa.jpg?raw=true' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

GMS-3DQA: Projection-based Grid Mini-patch Sampling for 3D Model Quality Assessment 
- **Zicheng Zhang**, Wei Sun, Houning Wu, Yingjie Zhou, Chunyi Li, Xiongkuo Min, Guangtao Zhai, Weisi Lin
- [**[Paper]**](https://arxiv.org/abs/2306.05658) [**[Repo]**](https://github.com/zzc-1998/GMS-3DQA)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2023</div><img src='https://github.com/zzc-1998/MD-VQA/blob/main/md-vqa.jpg?raw=true' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

MD-VQA: Multi-Dimensional Quality Assessment for UGC Live Videos 
- **Zicheng Zhang**, Wei Wu, Wei Sun, Dangyang Tu, Wei Lu, Xiongkuo Min, Ying Chen, Guangtao Zhai
- [**[Paper]**](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_MD-VQA_Multi-Dimensional_Quality_Assessment_for_UGC_Live_Videos_CVPR_2023_paper.pdf) [**[Repo]**](https://github.com/zzc-1998/MD-VQA)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IEEE TBC</div><img src='https://github.com/zzc-1998/zzc-1998.github.io/blob/main/images/6gdgqa.jpg?raw=true' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Quality-of-Experience Evaluation for Digital Twins in 6G Network Environments 
- **Zicheng Zhang**, Yingjie Zhou, Long Teng, Wei Sun, Chunyi Li, Xiongkuo Min, Xiao-Ping Zhang, Guangtao Zhai
- [**[Paper]**](https://ieeexplore.ieee.org/abstract/document/10381636/) 

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV Oral</div><img src='https://github.com/Q-Future/Co-Instruct/blob/main/teaser.png?raw=true' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Quality-of-Experience Evaluation for Digital Twins in 6G Network Environments 
- Haoning Wu\*, Hanwei Zhu\*, **Zicheng Zhang\***, Erli Zhang, Chaofeng Chen, Liang Liao, Chunyi Li, Annan Wang, Wenxiu Sun, Qiong Yan, Xiaohong Liu, Guangtao Zhai, Shiqi Wang, Weisi Lin
- [**[Paper]**](https://arxiv.org/pdf/2402.16641)  [**[Repo]**](https://github.com/Q-Future/Co-Instruct)

</div>
</div>


# üìñ Educations


- *2020.09 - Now*, PhD Student, [SJTU Multimedia Lab](https://multimedia.sjtu.edu.cn/), Shanghai Jiao Tong University, supervised by [Prof. Guangtao Zhai](https://scholar.google.ca/citations?user=E6zbSYgAAAAJ&hl=en). Research topics: Quality Assessment and Low-level Vision.
- *2016.09 - 2020.06*, B.S. in Information Science, SEIEE, Shanghai Jiao Tong University. 



# üíª Internships
- *2021.06 - 2021.09*, Bilibili, Shanghai, China.
- *2020.09 - 2021.03*, Huawei, Shanghai, China.

