{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "QICTEckAAAAJ&hl=zh-CN", "source": "AUTHOR_PROFILE_PAGE", "name": "Zicheng Zhang", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=QICTEckAAAAJ&citpid=2", "affiliation": "Shanghai AI Lab", "interests": ["Multi-modal LLM", "Quality assessment"], "email_domain": "@-", "homepage": "https://zzc-1998.github.io/", "citedby": 3349, "publications": {"QICTEckAAAAJ:35N4QoGY0k4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-align: Teaching lmms for visual scoring via discrete text-defined levels", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:35N4QoGY0k4C", "num_citations": 299, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=2101774103586253104,2373643679029913635", "cites_id": ["2101774103586253104", "2373643679029913635"]}, "QICTEckAAAAJ:RHpTSmoSYBkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Agiqa-3k: An open database for ai-generated image quality assessment", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:RHpTSmoSYBkC", "num_citations": 199, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=1590585229497860844,11376504162466552631", "cites_id": ["1590585229497860844", "11376504162466552631"]}, "QICTEckAAAAJ:4JMBOYKVnBMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-bench: A benchmark for general-purpose foundation models on low-level vision", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:4JMBOYKVnBMC", "num_citations": 195, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=11683847823892452807", "cites_id": ["11683847823892452807"]}, "QICTEckAAAAJ:_FM0Bhl9EiAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "No-reference quality assessment for 3d colored point cloud and mesh models", "pub_year": "2022"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:_FM0Bhl9EiAC", "num_citations": 184, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=7226118385281172144,662110680420857348", "cites_id": ["7226118385281172144", "662110680420857348"]}, "QICTEckAAAAJ:ns9cj8rnVeAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-instruct: Improving low-level visual abilities for multi-modality foundation models", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:ns9cj8rnVeAC", "num_citations": 128, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=1331342797383495989", "cites_id": ["1331342797383495989"]}, "QICTEckAAAAJ:QIV2ME_5wuYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MM-PCQA: Multi-modal learning for no-reference point cloud quality assessment", "pub_year": "2022"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:QIV2ME_5wuYC", "num_citations": 101, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=2356828192241074574", "cites_id": ["2356828192241074574"]}, "QICTEckAAAAJ:HDshCWvjkbEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A perceptual quality assessment exploration for aigc images", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:HDshCWvjkbEC", "num_citations": 95, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=17680456559474440899", "cites_id": ["17680456559474440899"]}, "QICTEckAAAAJ:oNZyr7d5Mn4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Evaluating point cloud from moving camera videos: A no-reference metric", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:oNZyr7d5Mn4C", "num_citations": 77, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=13163362378055911779,1559596029217764839,4157774563383771475,423754282972563", "cites_id": ["13163362378055911779", "1559596029217764839", "4157774563383771475", "423754282972563"]}, "QICTEckAAAAJ:TQgYirikUcIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MD-VQA: Multi-dimensional quality assessment for UGC live videos", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:TQgYirikUcIC", "num_citations": 77, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=4991661158330477600", "cites_id": ["4991661158330477600"]}, "QICTEckAAAAJ:M05iB0D1s5AC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards open-ended visual quality comparison", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:M05iB0D1s5AC", "num_citations": 72, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=7932693708176833645", "cites_id": ["7932693708176833645"]}, "QICTEckAAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A No-Reference Evaluation Metric for Low-Light Image Enhancement.", "pub_year": "2021"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:YsMSGLbcyi4C", "num_citations": 66, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=12471149730654990810", "cites_id": ["12471149730654990810"]}, "QICTEckAAAAJ:zA6iFVUQeVQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Gms-3dqa: Projection-based grid mini-patch sampling for 3d model quality assessment", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:zA6iFVUQeVQC", "num_citations": 57, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=5736515303062467116", "cites_id": ["5736515303062467116"]}, "QICTEckAAAAJ:-FonjvnnhkoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Deep neural network for blind visual quality assessment of 4K content", "pub_year": "2022"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:-FonjvnnhkoC", "num_citations": 56, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=12607363456787976851", "cites_id": ["12607363456787976851"]}, "QICTEckAAAAJ:PoWvk5oyLR8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A no-reference quality assessment metric for point cloud based on captured video sequences", "pub_year": "2022"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:PoWvk5oyLR8C", "num_citations": 55, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=14552609737648023396", "cites_id": ["14552609737648023396"]}, "QICTEckAAAAJ:e_rmSamDkqQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "NTIRE 2024 quality assessment of AI-generated content challenge", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:e_rmSamDkqQC", "num_citations": 52, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=13931840656786129264,11572929603447436573", "cites_id": ["13931840656786129264", "11572929603447436573"]}, "QICTEckAAAAJ:2P1L_qKh6hAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Quality-of-experience evaluation for digital twins in 6g network environments", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:2P1L_qKh6hAC", "num_citations": 49, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=7203172527770024021", "cites_id": ["7203172527770024021"]}, "QICTEckAAAAJ:nb7KW1ujOQ8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Advancing Zero-Shot Digital Human Quality Assessment through Text-Prompted Evaluation", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:nb7KW1ujOQ8C", "num_citations": 49, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=4898833103309553818,8582634832209730556,13461561714084408388", "cites_id": ["4898833103309553818", "8582634832209730556", "13461561714084408388"]}, "QICTEckAAAAJ:D03iK_w7-QYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Aigiqa-20k: A large database for ai-generated image quality assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:D03iK_w7-QYC", "num_citations": 48, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=14724390090137181388", "cites_id": ["14724390090137181388"]}, "QICTEckAAAAJ:sSrBHYA8nusC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-bench: A benchmark for multi-modal foundation models on low-level vision from single images to pairs", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:sSrBHYA8nusC", "num_citations": 43, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=15579030550564871419,11981963562388056804", "cites_id": ["15579030550564871419", "11981963562388056804"]}, "QICTEckAAAAJ:Tiz5es2fbqcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adaptive image quality assessment via teaching large multimodal model to compare", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:Tiz5es2fbqcC", "num_citations": 41, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=11519501046734869464", "cites_id": ["11519501046734869464"]}, "QICTEckAAAAJ:ldfaerwXgEUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Coupalign: Coupling word-pixel with sentence-mask alignments for referring image segmentation", "pub_year": "2022"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:ldfaerwXgEUC", "num_citations": 40, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=10393073040573897009", "cites_id": ["10393073040573897009"]}, "QICTEckAAAAJ:foquWX3nUaYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "NTIRE 2024 challenge on bracketing image restoration and enhancement: Datasets methods and results", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:foquWX3nUaYC", "num_citations": 38, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=11589826432344636576", "cites_id": ["11589826432344636576"]}, "QICTEckAAAAJ:hFOr9nPyWt4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Subjective and objective quality assessment for in-the-wild computer graphics images", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:hFOr9nPyWt4C", "num_citations": 35, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=8389612444294541607", "cites_id": ["8389612444294541607"]}, "QICTEckAAAAJ:4DMP91E08xMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A no-reference deep learning quality assessment method for super-resolution images based on frequency maps", "pub_year": "2022"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:4DMP91E08xMC", "num_citations": 33, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=10879833854635502601,5348605956517406720", "cites_id": ["10879833854635502601", "5348605956517406720"]}, "QICTEckAAAAJ:p2g8aNsByqUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A-bench: Are lmms masters at evaluating ai-generated images?", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:p2g8aNsByqUC", "num_citations": 31, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=16211564802552992113,1654216067590740339,16750795206780542154", "cites_id": ["16211564802552992113", "1654216067590740339", "16750795206780542154"]}, "QICTEckAAAAJ:7PzlFSSx8tAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Perceptual quality assessment for digital human heads", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:7PzlFSSx8tAC", "num_citations": 31, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=16755881198007546808", "cites_id": ["16755881198007546808"]}, "QICTEckAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A no-reference visual quality metric for 3d color meshes", "pub_year": "2021"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:W7OEmFMy1HYC", "num_citations": 31, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=3561936288639851202", "cites_id": ["3561936288639851202"]}, "QICTEckAAAAJ:ZeXyd9-uunAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Ddh-qa: A dynamic digital humans quality assessment database", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:ZeXyd9-uunAC", "num_citations": 29, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=4899463640672531787", "cites_id": ["4899463640672531787"]}, "QICTEckAAAAJ:M3ejUd6NZC8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A multi-dimensional aesthetic quality assessment model for mobile game images", "pub_year": "2021"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:M3ejUd6NZC8C", "num_citations": 28, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=1433627720048261298", "cites_id": ["1433627720048261298"]}, "QICTEckAAAAJ:tYavs44e6CUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "NTIRE 2025 challenge on short-form ugc video quality assessment and enhancement: Methods and results", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:tYavs44e6CUC", "num_citations": 27, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=931027243817995389", "cites_id": ["931027243817995389"]}, "QICTEckAAAAJ:Dip1O2bNi0gC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Subjective-aligned dataset and metric for text-to-video quality assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:Dip1O2bNi0gC", "num_citations": 27, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=7545731794688327996", "cites_id": ["7545731794688327996"]}, "QICTEckAAAAJ:f2IySw72cVMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "NTIRE 2024 challenge on short-form UGC video quality assessment: Methods and results", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:f2IySw72cVMC", "num_citations": 27, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=14010671446053919170", "cites_id": ["14010671446053919170"]}, "QICTEckAAAAJ:NhqRSupF_l8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lmm-pcqa: Assisting point cloud quality assessment with lmm", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:NhqRSupF_l8C", "num_citations": 26, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=9563793592119302859,13593736632062893973", "cites_id": ["9563793592119302859", "13593736632062893973"]}, "QICTEckAAAAJ:a9-T7VOCCH8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Guangtao Zhai, and Ning Liu. Subjective-aligned dateset and metric for text-to-video quality assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:a9-T7VOCCH8C", "num_citations": 26, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=15967814667690683856", "cites_id": ["15967814667690683856"]}, "QICTEckAAAAJ:IWHjjKOFINEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "EEP-3DQA: Efficient and effective projection-based 3D model quality assessment", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:IWHjjKOFINEC", "num_citations": 26, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=3519802327981275755", "cites_id": ["3519802327981275755"]}, "QICTEckAAAAJ:4fKUyHm3Qg0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Quality assessment in the era of large models: A survey", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:4fKUyHm3Qg0C", "num_citations": 25, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=663547636671105266", "cites_id": ["663547636671105266"]}, "QICTEckAAAAJ:WbkHhVStYXYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Misc: Ultra-low bitrate image semantic compression driven by large multimodal model", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:WbkHhVStYXYC", "num_citations": 24, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=15910158815344101194", "cites_id": ["15910158815344101194"]}, "QICTEckAAAAJ:u9iWguZQMMsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Enhancing blind video quality assessment with rich quality-aware features", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:u9iWguZQMMsC", "num_citations": 24, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=7528966499354264443", "cites_id": ["7528966499354264443"]}, "QICTEckAAAAJ:yD5IFk8b50cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A reduced-reference quality assessment metric for textured mesh digital humans", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:yD5IFk8b50cC", "num_citations": 24, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=11175783661160999017", "cites_id": ["11175783661160999017"]}, "QICTEckAAAAJ:Wp0gIr-vW9MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Perceptual quality assessment for fine-grained compressed images", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:Wp0gIr-vW9MC", "num_citations": 24, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=10121718553267407895,12090444225510079715", "cites_id": ["10121718553267407895", "12090444225510079715"]}, "QICTEckAAAAJ:lSLTfruPkqcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-boost: On visual quality assessment ability of low-level multi-modality foundation models", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:lSLTfruPkqcC", "num_citations": 23, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=11275383165513983919", "cites_id": ["11275383165513983919"]}, "QICTEckAAAAJ:YOwf2qJgpHMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A multiple attributes image quality database for smartphone camera photo quality assessment", "pub_year": "2020"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:YOwf2qJgpHMC", "num_citations": 23, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=3471447113107014596,14334384905571998384", "cites_id": ["3471447113107014596", "14334384905571998384"]}, "QICTEckAAAAJ:fQNAKQ3IYiAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Gaia: Rethinking action quality assessment for ai-generated videos", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:fQNAKQ3IYiAC", "num_citations": 22, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=14488099635006092658", "cites_id": ["14488099635006092658"]}, "QICTEckAAAAJ:abG-DnoFyZgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Large multi-modality model assisted ai-generated image quality assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:abG-DnoFyZgC", "num_citations": 22, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=9096707253802735123", "cites_id": ["9096707253802735123"]}, "QICTEckAAAAJ:g5m5HwL7SMYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-refine: A perceptual quality refiner for ai-generated image", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:g5m5HwL7SMYC", "num_citations": 22, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=9549853461719126765,2156957948716175195,826604054317909892", "cites_id": ["9549853461719126765", "2156957948716175195", "826604054317909892"]}, "QICTEckAAAAJ:J_g5lzvAfSwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Exploring the naturalness of ai-generated images", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:J_g5lzvAfSwC", "num_citations": 22, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=5388374132264335227", "cites_id": ["5388374132264335227"]}, "QICTEckAAAAJ:Y5dfb0dijaUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "NTIRE 2023 quality assessment of video enhancement challenge", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:Y5dfb0dijaUC", "num_citations": 20, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=5271017566461389650", "cites_id": ["5271017566461389650"]}, "QICTEckAAAAJ:_kc_bZDykSQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A full-reference quality assessment metric for fine-grained compressed images", "pub_year": "2021"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:_kc_bZDykSQC", "num_citations": 20, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=1278070431237666078", "cites_id": ["1278070431237666078"]}, "QICTEckAAAAJ:bFI3QPDXJZMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Deep portrait quality assessment. a NTIRE 2024 challenge survey", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:bFI3QPDXJZMC", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=16497614326456388763", "cites_id": ["16497614326456388763"]}, "QICTEckAAAAJ:j3f4tGmQtD8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A no-reference quality assessment method for digital human head", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:j3f4tGmQtD8C", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=11202091767668473402", "cites_id": ["11202091767668473402"]}, "QICTEckAAAAJ:u_35RYKgDlwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Thqa: A perceptual quality assessment database for talking heads", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:u_35RYKgDlwC", "num_citations": 18, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=11210937917537619353", "cites_id": ["11210937917537619353"]}, "QICTEckAAAAJ:5Ul4iDaHHb8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Benchmarking aigc video quality assessment: A dataset and unified model", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:5Ul4iDaHHb8C", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=10112422713395658588,4800719210835082653", "cites_id": ["10112422713395658588", "4800719210835082653"]}, "QICTEckAAAAJ:r0BpntZqJG4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Geometry-aware video quality assessment for dynamic digital human", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:r0BpntZqJG4C", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=5655016167166969127,9747281042539005347", "cites_id": ["5655016167166969127", "9747281042539005347"]}, "QICTEckAAAAJ:ILKRHgRFtOwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "On the usability (in) security of in-app browsing interfaces in mobile apps", "pub_year": "2021"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:ILKRHgRFtOwC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=2728292196289252532", "cites_id": ["2728292196289252532"]}, "QICTEckAAAAJ:vRqMK49ujn8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-ground: Image quality grounding with large multi-modality models", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:vRqMK49ujn8C", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=16953135405221935530", "cites_id": ["16953135405221935530"]}, "QICTEckAAAAJ:RGFaLdJalmkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Band-2k: Banding artifact noticeable database for banding detection and quality assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:RGFaLdJalmkC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=6871456243912669675", "cites_id": ["6871456243912669675"]}, "QICTEckAAAAJ:BqipwSGYUEgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A no-reference quality assessment metric for dynamic 3d digital human", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:BqipwSGYUEgC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=6348395976652171390", "cites_id": ["6348395976652171390"]}, "QICTEckAAAAJ:NJ774b8OgUMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Study of subjective and objective naturalness assessment of AI-generated images", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:NJ774b8OgUMC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=7249468789167148555", "cites_id": ["7249468789167148555"]}, "QICTEckAAAAJ:OU6Ihb5iCvQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dual-branch network for portrait image quality assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:OU6Ihb5iCvQC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=16225747423400282825,13598444123532301443", "cites_id": ["16225747423400282825", "13598444123532301443"]}, "QICTEckAAAAJ:vV6vV6tmYwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Investigation on the generation of high voltage quasi-square pulses with a specific two-node PFN-Marx circuit", "pub_year": "2020"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:vV6vV6tmYwMC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=18298012001926248702", "cites_id": ["18298012001926248702"]}, "QICTEckAAAAJ:BrmTIyaxlBUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VQA:Visual Question Answering for Video Quality Assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:BrmTIyaxlBUC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=14341035754778481431", "cites_id": ["14341035754778481431"]}, "QICTEckAAAAJ:L8Ckcad2t8MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Surveillance video quality assessment based on quality related retraining", "pub_year": "2022"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:L8Ckcad2t8MC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=11753728930343879287,8033182908798405540", "cites_id": ["11753728930343879287", "8033182908798405540"]}, "QICTEckAAAAJ:mB3voiENLucC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A full-reference quality assessment metric for cartoon images", "pub_year": "2022"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:mB3voiENLucC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=17350530308972122152,4235402086610843019", "cites_id": ["17350530308972122152", "4235402086610843019"]}, "QICTEckAAAAJ:0KyAp5RtaNEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Omnialign-v: Towards enhanced alignment of mllms with human preference", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:0KyAp5RtaNEC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=9485391959479377377", "cites_id": ["9485391959479377377"]}, "QICTEckAAAAJ:8AbLer7MMksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-Bench-Video: Benchmark the Video Quality Understanding of LMMs", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:8AbLer7MMksC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=9330726684753440965", "cites_id": ["9330726684753440965"]}, "QICTEckAAAAJ:geHnlv5EZngC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Subjective and objective quality-of-experience assessment for 3d talking heads", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:geHnlv5EZngC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=5930018615478936979", "cites_id": ["5930018615478936979"]}, "QICTEckAAAAJ:k8Z6L05lTy4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AIM 2024 challenge on UHD blind photo quality assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:k8Z6L05lTy4C", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=18167234776870463780", "cites_id": ["18167234776870463780"]}, "QICTEckAAAAJ:dshw04ExmUIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Light-vqa+: A video quality assessment model for exposure correction with vision-language guidance", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:dshw04ExmUIC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=1333745488597851025", "cites_id": ["1333745488597851025"]}, "QICTEckAAAAJ:-f6ydRqryjwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A deep learning-based multidimensional aesthetic quality assessment method for mobile game images", "pub_year": "2022"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:-f6ydRqryjwC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=1003147560781930641,10239997528583770858", "cites_id": ["1003147560781930641", "10239997528583770858"]}, "QICTEckAAAAJ:WZBGuue-350C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Wenhan Zhu, Quan Zhou, Jun He, Qiyuan Wang, Zicheng Zhang, Tao Wang, and Guangtao Zhai. Deep neural network for blind visual quality assessment of 4k content", "pub_year": "2022"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:WZBGuue-350C", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=5793256895353271807", "cites_id": ["5793256895353271807"]}, "QICTEckAAAAJ:eflP2zaiRacC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "R-Bench: Are your Large Multimodal Model Robust to Real-world Corruptions?", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:eflP2zaiRacC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=501049415724680955", "cites_id": ["501049415724680955"]}, "QICTEckAAAAJ:9Nmd_mFXekcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-eval-100k: Evaluating visual quality and alignment level for text-to-vision content", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:9Nmd_mFXekcC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=14884366476406503644,15706362403869436001,6287838838808524001", "cites_id": ["14884366476406503644", "15706362403869436001", "6287838838808524001"]}, "QICTEckAAAAJ:xtoqd-5pKcoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Guangtao Zhai, and Ning Liu. 2024. Subjective-Aligned Dateset and Metric for Text-to-Video Quality Assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:xtoqd-5pKcoC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=9101988015613323561", "cites_id": ["9101988015613323561"]}, "QICTEckAAAAJ:_xSYboBqXhAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AIS 2024 challenge on video quality assessment of user-generated content: Methods and results", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:_xSYboBqXhAC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=4834346261128285473", "cites_id": ["4834346261128285473"]}, "QICTEckAAAAJ:aqlVkmm33-oC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A cnn-based quality assessment method for pseudo 4k contents", "pub_year": "2021"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:aqlVkmm33-oC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=16673350955114626481,15312007555085436184", "cites_id": ["16673350955114626481", "15312007555085436184"]}, "QICTEckAAAAJ:eJXPG6dFmWUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "3dgcqa: A quality assessment database for 3d ai-generated contents", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:eJXPG6dFmWUC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=15576729185771090975", "cites_id": ["15576729185771090975"]}, "QICTEckAAAAJ:-_dYPAW6P2MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Redundancy principles for MLLMs benchmarks", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:-_dYPAW6P2MC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=17662109533613563953,14144370014589858412,678269580137109119", "cites_id": ["17662109533613563953", "14144370014589858412", "678269580137109119"]}, "QICTEckAAAAJ:Z5m8FVwuT1cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning hazing to dehazing: Towards realistic haze generation for real-world image dehazing", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:Z5m8FVwuT1cC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=14792356802055238374", "cites_id": ["14792356802055238374"]}, "QICTEckAAAAJ:olpn-zPbct0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Human-activity agv quality assessment: A benchmark dataset and an objective evaluation metric", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:olpn-zPbct0C", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=718290569485066755", "cites_id": ["718290569485066755"]}, "QICTEckAAAAJ:iH-uZ7U-co4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Simple baselines for projection-based full-reference and no-reference point cloud quality assessment", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:iH-uZ7U-co4C", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=11388601826081616510,2255886826503629564", "cites_id": ["11388601826081616510", "2255886826503629564"]}, "QICTEckAAAAJ:B3FOqHPlNUQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Assessing uhd image quality from aesthetics, distortions, and saliency", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:B3FOqHPlNUQC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=12211320417286116263", "cites_id": ["12211320417286116263"]}, "QICTEckAAAAJ:SeFeTyx0c_EC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Perceptual Quality Assessment for Point Clouds Point Clouds: A Survey", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:SeFeTyx0c_EC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=8968965061511967504,15256167244020314998", "cites_id": ["8968965061511967504", "15256167244020314998"]}, "QICTEckAAAAJ:hC7cP41nSMkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Blind surveillance image quality assessment via deep neural network combined with the visual saliency", "pub_year": "2022"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:hC7cP41nSMkC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=5873145089181044224", "cites_id": ["5873145089181044224"]}, "QICTEckAAAAJ:evX43VCCuoAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ReLI-QA: A Multidimensional Quality Assessment Dataset for Relighted Human Heads", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:evX43VCCuoAC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=5191212748695630427", "cites_id": ["5191212748695630427"]}, "QICTEckAAAAJ:N5tVd3kTz84C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SG-JND: Semantic-guided just noticeable distortion predictor for image compression", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:N5tVd3kTz84C", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=10884097299199961398", "cites_id": ["10884097299199961398"]}, "QICTEckAAAAJ:XiVPGOgt02cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AIM 2024 challenge on compressed video quality assessment: methods and results", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:XiVPGOgt02cC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=14518618636480647307", "cites_id": ["14518618636480647307"]}, "QICTEckAAAAJ:a0OBvERweLwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Attentionlut: Attention fusion-based canonical polyadic lut for real-time image enhancement", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:a0OBvERweLwC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=17154705191380209231", "cites_id": ["17154705191380209231"]}, "QICTEckAAAAJ:kuK5TVdYjLIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Guangtao Zhai, and Weisi Lin", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:kuK5TVdYjLIC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=10220117428805059783", "cites_id": ["10220117428805059783"]}, "QICTEckAAAAJ:mVmsd5A6BfQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Subjective quality assessment for images generated by computer graphics", "pub_year": "2022"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:mVmsd5A6BfQC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=11150544344144572536", "cites_id": ["11150544344144572536"]}, "QICTEckAAAAJ:b0M2c_1WBrUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "G-refine: A general quality refiner for text-to-image generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:b0M2c_1WBrUC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=8939972674167105647", "cites_id": ["8939972674167105647"]}, "QICTEckAAAAJ:KUbvn5osdkgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, and Guangtao Zhai. Memo-bench: A multiple benchmark for text-to-image and multimodal large language models on human emotion analysis", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:KUbvn5osdkgC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=339771975275979084", "cites_id": ["339771975275979084"]}, "QICTEckAAAAJ:hMod-77fHWUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "BH-VQA: blind high frame rate video quality assessment", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:hMod-77fHWUC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=5176053163775259280", "cites_id": ["5176053163775259280"]}, "QICTEckAAAAJ:EkHepimYqZsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision.(2023)", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:EkHepimYqZsC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=3223508715790384066", "cites_id": ["3223508715790384066"]}, "QICTEckAAAAJ:0N-VGjzr574C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Human-Centric Evaluation for Foundation Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:0N-VGjzr574C", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=18047491284257616104", "cites_id": ["18047491284257616104"]}, "QICTEckAAAAJ:4MWp96NkSFoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Envisioning beyond the pixels: Benchmarking reasoning-informed visual editing", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:4MWp96NkSFoC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=2579671501630690559", "cites_id": ["2579671501630690559"]}, "QICTEckAAAAJ:q3oQSFYPqjQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MEMO-Bench: A Multiple Benchmark for Text-to-Image and Multimodal Large Language Models on Human Emotion Analysis", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:q3oQSFYPqjQC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=10677392357687861475", "cites_id": ["10677392357687861475"]}, "QICTEckAAAAJ:08ZZubdj9fEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Paps-ovqa: Projection-aware patch sampling for omnidirectional video quality assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:08ZZubdj9fEC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=13216107079083487738", "cites_id": ["13216107079083487738"]}, "QICTEckAAAAJ:NaGl4SEjCO4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FS-BAND: A frequency-sensitive banding detector", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:NaGl4SEjCO4C", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=12941023393766699680", "cites_id": ["12941023393766699680"]}, "QICTEckAAAAJ:2KloaMYe4IUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rawiw: Raw image watermarking robust to isp pipeline", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:2KloaMYe4IUC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=2953812531424160497", "cites_id": ["2953812531424160497"]}, "QICTEckAAAAJ:tuHXwOkdijsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Chest CT-IQA: A multi-task model for chest CT image quality assessment and classification", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:tuHXwOkdijsC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=15438606973786507667", "cites_id": ["15438606973786507667"]}, "QICTEckAAAAJ:sNmaIFBj_lkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, and Guangtao Zhai,“", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:sNmaIFBj_lkC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=2630672924529256300", "cites_id": ["2630672924529256300"]}, "QICTEckAAAAJ:Ri6SYOTghG4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, and Guangtao Zhai. Assessing uhd image quality from aesthetics, distortions, and saliency", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:Ri6SYOTghG4C", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=14539213155029846902", "cites_id": ["14539213155029846902"]}, "QICTEckAAAAJ:zLWjf1WUPmwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Guangtao Zhai, Chunyi Li, Tengchuan Kou, Wei Sun, Haoning Wu, Yixuan Gao, Yuqin Cao, Zicheng Zhang, et al. Ntire 2024 quality assessment of ai-generated content …", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:zLWjf1WUPmwC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=9097020021210929447", "cites_id": ["9097020021210929447"]}, "QICTEckAAAAJ:t7zJ5fGR-2UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Guangtao Zhai, Chunyi Li, Tengchuan Kou, Wei Sun, Haoning Wu, Yixuan Gao, Yuqin Cao, Zicheng Zhang, et al. 2024. NTIRE 2024 Quality Assessment of AI-Generated …", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:t7zJ5fGR-2UC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=18242091789705254737", "cites_id": ["18242091789705254737"]}, "QICTEckAAAAJ:e5wmG9Sq2KIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Distinguishing computer-generated images from photographic images: a texture-aware deep learning-based method", "pub_year": "2022"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:e5wmG9Sq2KIC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=55116544529204278", "cites_id": ["55116544529204278"]}, "QICTEckAAAAJ:XvxMoLDsR5gC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Tao Wang, Wei Lu, Wenhan Zhu, and Guangtao Zhai. 2021. A no-reference visual quality metric for 3d color meshes"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:XvxMoLDsR5gC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=957694150048993890", "cites_id": ["957694150048993890"]}, "QICTEckAAAAJ:8d8msizDQcsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AIBENCH: TOWARDS TRUSTWORTHY EVALUA-TION UNDER THE 45 LAW"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:8d8msizDQcsC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=8775769087139008766", "cites_id": ["8775769087139008766"]}, "QICTEckAAAAJ:bz8QjSJIRt4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, and Guangtao Zhai. Bh-vqa: Blind high frame rate video quality assessment"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:bz8QjSJIRt4C", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=17816372711769298617", "cites_id": ["17816372711769298617"]}, "QICTEckAAAAJ:2VqYfGB8ITEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Just Noticeable Difference for Large Multimodal Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:2VqYfGB8ITEC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=4859039226231572308", "cites_id": ["4859039226231572308"]}, "QICTEckAAAAJ:l7t_Zn2s7bgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Hazeclip: Towards language guided real-world image dehazing", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:l7t_Zn2s7bgC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=13500029096025719911", "cites_id": ["13500029096025719911"]}, "QICTEckAAAAJ:uc_IGeMz5qoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multi-Dimensional Quality Assessment for Text-to-3D Assets: Dataset and Model", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:uc_IGeMz5qoC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=17987185628072098132", "cites_id": ["17987185628072098132"]}, "QICTEckAAAAJ:mlAyqtXpCwEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Haodong Duan, Kai Chen, and Guangtao Zhai. Redundancy principles for mllms benchmarks", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:mlAyqtXpCwEC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=8076143516460537526", "cites_id": ["8076143516460537526"]}, "QICTEckAAAAJ:_axFR9aDTf0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "An Empirical Study for Efficient Video Quality Assessment", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:_axFR9aDTf0C", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=11662679122721822369", "cites_id": ["11662679122721822369"]}, "QICTEckAAAAJ:yB1At4FlUx8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Image Quality Assessment: From Human to Machine Preference", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:yB1At4FlUx8C", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=8327132042548807158", "cites_id": ["8327132042548807158"]}, "QICTEckAAAAJ:K3LRdlH-MEoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Optimizing projection-based point cloud quality assessment with human preferred viewpoints selection", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:K3LRdlH-MEoC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=3829228569111670335", "cites_id": ["3829228569111670335"]}, "QICTEckAAAAJ:738O_yMBCRsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "CMC-Bench: Towards a New Paradigm of Visual Signal Compression", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:738O_yMBCRsC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=16860410742694368289", "cites_id": ["16860410742694368289"]}, "QICTEckAAAAJ:FPJr55Dyh1AC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Weisi Lin, and Guangtao Zhai", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:FPJr55Dyh1AC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=11790195690630543502", "cites_id": ["11790195690630543502"]}, "QICTEckAAAAJ:70eg2SAEIzsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mv-vvqa: Multi-view learning for no-reference volumetric video quality assessment", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:70eg2SAEIzsC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=6070310500585111088", "cites_id": ["6070310500585111088"]}, "QICTEckAAAAJ:fEOibwPWpKIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Wei Lu, Zicheng Zhang, and Guangtao Zhai. 2021. A multi-dimensional aesthetic quality assessment model for mobile game images", "pub_year": "2021"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:fEOibwPWpKIC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=6355875502688341852", "cites_id": ["6355875502688341852"]}, "QICTEckAAAAJ:FAceZFleit8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "CT-PCQA: A Convolutional Neural Network and Transformer combined Method for Point Cloud Quality Assessment", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:FAceZFleit8C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=12245564238691971731", "cites_id": ["12245564238691971731"]}, "QICTEckAAAAJ:edDO8Oi4QzsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Affordance Benchmark for MLLMs", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:edDO8Oi4QzsC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=13079867362245835370", "cites_id": ["13079867362245835370"]}, "QICTEckAAAAJ:Ug5p-4gJ2f0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Improve MLLM Benchmark Efficiency through Interview", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:Ug5p-4gJ2f0C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=12017947538965706346", "cites_id": ["12017947538965706346"]}, "QICTEckAAAAJ:LI9QrySNdTsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Who is a Better Imitator: Subjective and Objective Quality Assessment of Animated Humans", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:LI9QrySNdTsC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=12697257227834896813", "cites_id": ["12697257227834896813"]}, "QICTEckAAAAJ:35r97b3x0nAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MM-PCQA+: Advancing Multi-Modal Learning for Point Cloud Quality Assessment", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:35r97b3x0nAC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=13264136437773373978", "cites_id": ["13264136437773373978"]}, "QICTEckAAAAJ:D_sINldO8mEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Explore the hallucination on low-level perception for mllms", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:D_sINldO8mEC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=4257936413426203978", "cites_id": ["4257936413426203978"]}, "QICTEckAAAAJ:BwyfMAYsbu0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Creation-mmbench: Assessing context-aware creative intelligence in mllm", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:BwyfMAYsbu0C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=10974613209780086546", "cites_id": ["10974613209780086546"]}, "QICTEckAAAAJ:IRz6iEL74y4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, and Guangtao Zhai. Aghi-qa: A subjective-aligned dataset and metric for ai-generated human images", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:IRz6iEL74y4C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=7952948809801400169", "cites_id": ["7952948809801400169"]}, "QICTEckAAAAJ:WJVC3Jt7v1AC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, and Guangtao Zhai. Q-agent: Quality-driven chain-of-thought image restoration agent through robust multimodal large language model", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:WJVC3Jt7v1AC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=6012786387453675019", "cites_id": ["6012786387453675019"]}, "QICTEckAAAAJ:kh2fBNsKQNwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, and Guangtao Zhai. Puzzlebench: A fully dynamic evaluation framework for large multimodal models on puzzle solving", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:kh2fBNsKQNwC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=15693702599406421668", "cites_id": ["15693702599406421668"]}, "QICTEckAAAAJ:PVjk1bu6vJQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Leveraging Multimodal Large Language Models for Joint Discrete and Continuous Evaluation in Text-to-Image Alignment", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:PVjk1bu6vJQC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=6300541572876701130", "cites_id": ["6300541572876701130"]}, "QICTEckAAAAJ:gsN89kCJA0AC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, and Guangtao Zhai. Hazeclip: Towards language guided real-world image dehazing", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:gsN89kCJA0AC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=16696925353559321632", "cites_id": ["16696925353559321632"]}, "QICTEckAAAAJ:_Re3VWB3Y0AC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "IllusionBench: A Large-scale and Comprehensive Benchmark for Visual Illusion Understanding in Vision-Language Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:_Re3VWB3Y0AC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=4715744487292368855", "cites_id": ["4715744487292368855"]}, "QICTEckAAAAJ:LPZeul_q3PIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "T2i-scorer: Quantitative evaluation on text-to-image generation via fine-tuned large multi-modal models", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:LPZeul_q3PIC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=11554666882836879525", "cites_id": ["11554666882836879525"]}, "QICTEckAAAAJ:4fGpz3EwCPoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Zicheng Zhang, Chunyi Li, Zijian Chen, Puyi Wang, Zhongpeng Ji, et al. 2024. Benchmarking AIGC Video Quality Assessment: A Dataset and Unified Model", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:4fGpz3EwCPoC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=8144222616629545921", "cites_id": ["8144222616629545921"]}, "QICTEckAAAAJ:86PQX7AUzd4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:86PQX7AUzd4C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=9095107915516586694", "cites_id": ["9095107915516586694"]}, "QICTEckAAAAJ:URolC5Kub84C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Xiaohong Liu, Guangtao Zhai, and Weisi Lin. 2024. CMC-Bench: Towards a New Paradigm of Visual Signal Compression", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:URolC5Kub84C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=15858228133494372275", "cites_id": ["15858228133494372275"]}, "QICTEckAAAAJ:uJ-U7cs_P_0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Xiaohong Liu, Chunyi Li, Haoning Wu, Weisi Lin, Ning Liu, and Guangtao Zhai. 2024. Optimizing Projection-Based Point Cloud Quality Assessment With Human Preferred …", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:uJ-U7cs_P_0C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=10357886782096347528", "cites_id": ["10357886782096347528"]}, "QICTEckAAAAJ:6ZxmRoH8BuwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Fengyu Sun, Shangling Jui, Weisi Lin, and Guangtao Zhai. Q-boost: On visual quality assessment ability of low-level multi-modality foundation models", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:6ZxmRoH8BuwC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=4538831832138230274", "cites_id": ["4538831832138230274"]}, "QICTEckAAAAJ:hCrLmN-GePgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Qiyuan Wang, Jun He, Quan Zhou and Guangtao Zhai. MM-PCQA: Multi-modal learning for noreference point cloud quality assessment", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:hCrLmN-GePgC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=2917148331224938132", "cites_id": ["2917148331224938132"]}, "QICTEckAAAAJ:vbGhcppDl1QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Fengyu Sun, Shangling Jui, et al", "pub_year": "2023"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:vbGhcppDl1QC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=12688156684774794026", "cites_id": ["12688156684774794026"]}, "QICTEckAAAAJ:4hFrxpcac9AC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Qi Jia, and Guangtao Zhai. Aibench: Towards trustworthy evaluation under the 45 law"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:4hFrxpcac9AC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=709272669115392410", "cites_id": ["709272669115392410"]}, "QICTEckAAAAJ:0izLItjtcgwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Who is a Better Talker: Subjective and Objective Quality Assessment for AI-Generated Talking Heads", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:0izLItjtcgwC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=2149420967519256624", "cites_id": ["2149420967519256624"]}, "QICTEckAAAAJ:anf4URPfarAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "The ever-evolving science exam", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:anf4URPfarAC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=7188403426340240318", "cites_id": ["7188403426340240318"]}, "QICTEckAAAAJ:lmc2jWPfTJgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Perceptual Quality Assessment for Embodied AI", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:lmc2jWPfTJgC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=6086140341102661755", "cites_id": ["6086140341102661755"]}, "QICTEckAAAAJ:MLfJN-KU85MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "LOVE: Benchmarking and Evaluating Text-to-Video Generation and Video-to-Text Interpretation", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:MLfJN-KU85MC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=4616723609634941314", "cites_id": ["4616723609634941314"]}, "QICTEckAAAAJ:hMsQuOkrut0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AGHI-QA: A Subjective-Aligned Dataset and Metric for AI-Generated Human Images", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:hMsQuOkrut0C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=5259831987483969025", "cites_id": ["5259831987483969025"]}, "QICTEckAAAAJ:g3aElNc5_aQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PuzzleBench: A Fully Dynamic Evaluation Framework for Large Multimodal Models on Puzzle Solving", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:g3aElNc5_aQC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=636449566557595960", "cites_id": ["636449566557595960"]}, "QICTEckAAAAJ:b1wdh0AR-JQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards Explainable Partial-AIGC Image Quality Assessment", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:b1wdh0AR-JQC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=11209745774244767622", "cites_id": ["11209745774244767622"]}, "QICTEckAAAAJ:EYYDruWGBe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-Agent: Quality-Driven Chain-of-Thought Image Restoration Agent through Robust Multimodal Large Language Model", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:EYYDruWGBe4C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=246910257141270835", "cites_id": ["246910257141270835"]}, "QICTEckAAAAJ:ML0RJ9NH7IQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mitigating Low-Level Visual Hallucinations Requires Self-Awareness: Database, Model and Training Strategy", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:ML0RJ9NH7IQC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=3766866832355859384", "cites_id": ["3766866832355859384"]}, "QICTEckAAAAJ:nrtMV_XWKgEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Teaching lmms for image quality scoring and interpreting", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:nrtMV_XWKgEC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=2435785177873578153", "cites_id": ["2435785177873578153"]}, "QICTEckAAAAJ:tS2w5q8j5-wC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "G-refine: A general refiner for text-to-image generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:tS2w5q8j5-wC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=17547060149145274630", "cites_id": ["17547060149145274630"]}, "QICTEckAAAAJ:umqufdRvDiIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MI3S: A multimodal large language model assisted quality assessment framework for AI-generated talking heads", "pub_year": "2026"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:umqufdRvDiIC", "num_citations": 0}, "QICTEckAAAAJ:HtEfBTGE9r8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Benchmarking Multi-dimensional AIGC Video Quality Assessment: A Dataset and Unified Model", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:HtEfBTGE9r8C", "num_citations": 0}, "QICTEckAAAAJ:4vMrXwiscB8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VQualA 2025 Challenge on Face Image Quality Assessment: Methods and Results", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:4vMrXwiscB8C", "num_citations": 0}, "QICTEckAAAAJ:OTTXONDVkokC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MedOmni-45 {\\deg}: A Safety-Performance Benchmark for Reasoning-Oriented LLMs in Medicine", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:OTTXONDVkokC", "num_citations": 0}, "QICTEckAAAAJ:_5tno0g5mFcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "User-centric Subjective Leaderboard by Customizable Reward Modeling", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:_5tno0g5mFcC", "num_citations": 0}, "QICTEckAAAAJ:DUooU5lO8OsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AU-IQA: A Benchmark Dataset for Perceptual Quality Assessment of AI-Enhanced User-Generated Content", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:DUooU5lO8OsC", "num_citations": 0}, "QICTEckAAAAJ:mNrWkgRL2YcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Static and Plugged: Make Embodied Evaluation Simple", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:mNrWkgRL2YcC", "num_citations": 0}, "QICTEckAAAAJ:QYdC8u9Cj1oC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Who is a Better Player: LLM against LLM", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:QYdC8u9Cj1oC", "num_citations": 0}, "QICTEckAAAAJ:dBIO0h50nwkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Refine-IQA: Multi-Stage Reinforcement Finetuning for Perceptual Image Quality Assessment", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:dBIO0h50nwkC", "num_citations": 0}, "QICTEckAAAAJ:ClCfbGk0d_YC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GOBench: Benchmarking Geometric Optics Generation and Understanding of MLLMs", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:ClCfbGk0d_YC", "num_citations": 0}, "QICTEckAAAAJ:ruyezt5ZtCIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Scaling-up Perceptual Video Quality Assessment", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:ruyezt5ZtCIC", "num_citations": 0}, "QICTEckAAAAJ:NXb4pA-qfm4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "LPerceptual Quality Assessment of AI Generated Content Videos: a Dataset and Benchmark", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:NXb4pA-qfm4C", "num_citations": 0}, "QICTEckAAAAJ:epqYDVWIO7EC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Information Density Principle for MLLM Benchmarks", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:epqYDVWIO7EC", "num_citations": 0}, "QICTEckAAAAJ:YohjEiUPhakC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:YohjEiUPhakC", "num_citations": 0}, "QICTEckAAAAJ:VaXvl8Fpj5cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment", "pub_year": "2025"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:VaXvl8Fpj5cC", "num_citations": 0}, "QICTEckAAAAJ:pyW8ca7W8N0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Subjective-aligned dataset and metric for text-to-video quality assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:pyW8ca7W8N0C", "num_citations": 0}, "QICTEckAAAAJ:XoXfffV-tXoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Compression-RQ-VQA: Leveraging Rich Quality-Aware Features for Compressed Video Quality Assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:XoXfffV-tXoC", "num_citations": 0}, "QICTEckAAAAJ:TIZ-Mc8IlK0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Jia Wang, and Guangtao Zhai. Reli-qa: A multidimensional quality assessment dataset for relighted human heads", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:TIZ-Mc8IlK0C", "num_citations": 0}, "QICTEckAAAAJ:XD-gHx7UXLsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "NTIRE 2024 challenge on bracketing image restoration and enhancement: Datasets methods and results", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:XD-gHx7UXLsC", "num_citations": 0}, "QICTEckAAAAJ:j8SEvjWlNXcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Zicheng Zhang, Chunyi Li, Zijian Chen, Puyi Wang, Zhongpeng Ji, et al. Benchmarking aigc video quality assessment: A dataset and unified model", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:j8SEvjWlNXcC", "num_citations": 0}, "QICTEckAAAAJ:EUQCXRtRnyEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "NTIRE 2024 quality assessment of AI-generated content challenge", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:EUQCXRtRnyEC", "num_citations": 0}, "QICTEckAAAAJ:dfsIfKJdRG4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Evaluating point cloud from moving camera videos: A no-reference metric", "pub_year": "2024"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:dfsIfKJdRG4C", "num_citations": 0}, "QICTEckAAAAJ:qUcmZB5y_30C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Deep neural network for blind visual quality assessment of 4K content", "pub_year": "2022"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:qUcmZB5y_30C", "num_citations": 0}, "QICTEckAAAAJ:dhFuZR0502QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A no-reference quality assessment metric for point cloud based on captured video sequences", "pub_year": "2022"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:dhFuZR0502QC", "num_citations": 0}, "QICTEckAAAAJ:4OULZ7Gr8RgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "No-reference quality assessment for 3d colored point cloud and mesh models", "pub_year": "2022"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:4OULZ7Gr8RgC", "num_citations": 0}, "QICTEckAAAAJ:SpbeaW3--B0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xiongkuo Min, Wei Lu, Tao Wang, Ning Liu, and Guangtao Zhai,“A no-reference quality assessment metric for point cloud based on captured video sequences,”", "pub_year": "2022"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:SpbeaW3--B0C", "num_citations": 0}, "QICTEckAAAAJ:HIFyuExEbWQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SI23DCQA: Perceptual Quality Assessment of Single Image-to-3D Content"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:HIFyuExEbWQC", "num_citations": 0}, "QICTEckAAAAJ:9c2xU6iGI7YC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "CAP: An Advanced No-Reference Quality Assessment Method for AI-Generated 3D Meshes"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:9c2xU6iGI7YC", "num_citations": 0}, "QICTEckAAAAJ:IUKN3-7HHlwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VIP-PCQA: A Multi-Modal Framework for No-reference Point Cloud Quality Assessment"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:IUKN3-7HHlwC", "num_citations": 0}, "QICTEckAAAAJ:BUYA1_V_uYcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-Instruct"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:BUYA1_V_uYcC", "num_citations": 0}, "QICTEckAAAAJ:AvfA0Oy_GE0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Supplementary Materials for GAIA: Rethinking Action Quality Assessment for AI-Generated Videos"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:AvfA0Oy_GE0C", "num_citations": 0}, "QICTEckAAAAJ:uWiczbcajpAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards Open-ended Visual Quality Comparison Supplementary Material"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:uWiczbcajpAC", "num_citations": 0}, "QICTEckAAAAJ:tzM49s52ZIMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "IllusionBench: 一个大规模且全面的视觉幻觉理解基准, 用于视觉-语言模型"}, "filled": false, "author_pub_id": "QICTEckAAAAJ:tzM49s52ZIMC", "num_citations": 0}}, "citedby5y": 3348, "hindex": 28, "hindex5y": 28, "i10index": 75, "i10index5y": 75, "cites_per_year": {"2020": 9, "2021": 9, "2022": 84, "2023": 303, "2024": 1314, "2025": 1594}, "updated": "2025-09-26 08:22:52.801797"}